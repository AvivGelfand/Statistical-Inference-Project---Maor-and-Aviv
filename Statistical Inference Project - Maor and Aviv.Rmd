---
title: "Inferencial Statistics Analysis Project"
author: "Aviv Gelfand and Maor Moshe  -  03/12/2022"
output:
  html_document: 
    fig_height: 4
    df_print: kable
    fig_width: 6
  word_document: default
editor_options:
  chunk_output_type: console
---


#### Recall of our previous project
Recall that in the previews project we used WHO table of Average BMI and life expectancy for 177 countries in the world.
[Source](https://www.kaggle.com/datasets/kumarajarshi/life-expectancy-who?resource=download).

**Predicted / dependent variable Y**: Life expectancy - refers to average number of years a person can expect to live in a country.

**Undependable variable X**: BMI - Body Mass Index units. A calculation using a person's height and weight. 

**We hypothesized** that BMI is an explanatory variable for a person's life expectancy. 


```{r echo=FALSE, message=FALSE, warning=FALSE }
# getwd()
setwd("C:/Users/avivg/OneDrive/Documents/R/Statistical Analysis Course/Lab2") #Aviv's setwd
# setwd("C:/") #Maor's setwd, *aviv* commit it when you working
df <- read.csv("WHO_BMI_2015.csv")
Life.expectancy <- df$Life.expectancy
BMI <- df$BMI
# head(df)
# na.omit(df)
# plot(main = "Clean Scatter Plot",BMI,Life.expectancy, col="blue")
# abline(v=10, col="red") 

# setBasic <- function (){
#   setwd("C:/Users/avivg/OneDrive/Documents/R/Statistical Analysis Course/Lab")
# df <- read.csv("WHO_BMI_2015.csv")
# Life.expectancy <- df$Life.expectancy
# BMI <- df$BMI
# }
# setBasic()
```

#### 1) Point Estimators
```{r  echo=FALSE, ,message=FALSE, warning=FALSE}
#Q1 #Assume Y distributs norm and asses E(y) and var(y)
# by MLE method:
Y_mu_hat <- mean(Life.expectancy)
# Y_mu_hat

Y_sig_square_hat <- var(Life.expectancy)
# Y_sig_square_hat
# sqrt(Y_sig_square_hat)


#Hanfanim - moment method :
Y_mu_hat_mom <- mean(Life.expectancy)
# Y_mu_hat_mom

Ey_squre <- Y_mu_hat_mom^2
y_squre <- mean(Life.expectancy^2)
Y_sig_squre_hat_mom_MLE <- y_squre - Ey_squre
# Y_sig_squre_hat_mom

```
##### a) Estimating Expectency and Variance Y
נניח שלערך החזוי, תוחלת החיים הממוצעת במדינה, התפלגות נורמלית. אז נגדיר אומד לתוחלת לפי שיטת הנראות המקסימלית או לפי שיטת המומנטים (אותה דרך).

$\hat{\mu_y} := \overline{Y} = \frac{1}{n} \sum_{i = 1}^{n}y_i$ = `r round(Y_mu_hat,2)`

ונגדיר אומד לשונות לפי שיטת הנראות המקסימלית

$\hat{\sigma^2_y} := \overline{Y^2} - \overline{Y}^2= \frac{1}{n} \sum_{i = 1}^{n}(y_i-\overline{Y})^2$  = `r round(Y_sig_squre_hat_mom_MLE,2)`

בנוסף, למדנו בכיתה על אומד חסר הטייה מקובל לשונות להתפלגות נורמלית כך ש:

$\hat{\sigma^2_y} := S^2_n :=\frac{1}{n-1}\sum_{i = 1}^{n}(y_i-\overline{Y})^2$  = `r round(var(Life.expectancy),2)`

Both of the estimators are unbiased. We can see that mom estimator has smaller variety and hence smaller mse rate. therefore we will proceed the assignment with mom astimator.


```{r echo=FALSE, message=FALSE, warning=FALSE }
m <- min(BMI)
W<- BMI-m
W <-sort(W)
# W
# Moment method 
a_hat_moment <- (mean(W)^2)/((mean(W^2))-(mean(W)^2))
# a_hat_moment
# mean(BMI)^2
lambda_hat_moment <- (mean(W))/((mean(W^2))-(mean(W)^2))
# lambda_hat_moment
```

##### b) Estimating Expectency and Variance of X using Gamma
We denote the independent variable, BMI as $X$, then: 

Let $m=min(X)$ and Let $W:=X-m$ and assume $W \sim Gamma(\alpha, \lambda)$

Then, by the formulas we prooved in class, the point estimator of $\alpha$ would be:
$\hat{\alpha}=\frac{\overline{W}^2}{\overline{W}^2-\overline{W^2}}$

And the point estimator of $\lambda$ would be:
$\hat{\lambda}=\frac{\overline{W}^2}{\overline{W}^2-\overline{W^2}}$


```{r echo=FALSE, message=FALSE, warning=FALSE }
#1.c
quantiles <- c(0.1,0.5,0.75,0.9)
quants <- c(0.1,0.5,0.75,0.9)

w_quants <- qgamma(quantiles, shape = a_hat_moment, scale = lambda_hat_moment)
# quants_X
X_quants= quantile(BMI, probs = quantiles) #for x
Y_quants= quantile(Life.expectancy, probs=quantiles) # for y

#1.d
# quantile(W, probs=quants)
# whit out hypothesis test, it seems that there is corrletion between the cars
library(dplyr)

df1 = data.frame( rbind(X_quants , Y_quants, w_quants))
colnames(df1) <- c(0.1,0.5,0.75,0.9)
df1
```

##### c-d) Quantiles of X,Y and W
**Quantiles**:  [0.1,0.5,0.75,0.9]
Table: 

$X:$ [`r round(quantile(BMI, probs = quants),2)`] 

$Y:$ [`r round( quantile( Life.expectancy, probs=quants), 2)`]

$W:$ [`r round(c(1,1,1,1,1),2)`]




```{r echo=FALSE, message=FALSE, warning=FALSE }

#1.e hanfanim 2
# # percentiles ??
# gamma_percentiles <- qgamma(percentiles, shape = a_hat_moment, scale = lambda_hat_moment)
# plot(ecdf(W))
# points(ecdf(gamma_percentiles[1:100]),col='red')
# 
# 
# # Compute ECDFs
# W_ecdf <- ecdf(W)
# gamma_ecdf <- ecdf(gamma_percentiles[1:100])
# 
# # Set up the plot
# plot(W_ecdf, xlim = c(min(W, gamma_percentiles[1:100]), max(W, gamma_percentiles[1:100])),col='lightgreen' ,xlab = "Value", ylab = "ECDF", main = "theortical precentials to gamma precentails Comparison")
# 
# # Add the second ECDF to the plot
# lines(gamma_ecdf, col = "lightblue")
# 
# # Add a legend
# legend("bottomright", c("W", "gamma_percentiles"), col = c("blue", "red"), lty = 1)
```

# Question 2 - Confidence Intervals


```{r  Q2 }
# Question 2 - CI 

## for the expectancy
mean(Life.expectancy)
qnorm(0.985)
Upper_CI_miu_y <- mean(Life.expectancy) + qnorm(0.985)*sd(Life.expectancy)/(sqrt(length(Life.expectancy)))
Upper_CI_miu_y

Lower_CI_miu_y <-mean(Life.expectancy) - qnorm(0.985)*sd(Life.expectancy)/(sqrt(length(Life.expectancy))) 
Lower_CI_miu_y
Miu_CI <- c(Lower_CI_miu_y,Upper_CI_miu_y) 
Miu_CI #70.50 #73.14
# we can see that the value of x_hat is in the range 
mean(Life.expectancy)
 
## for the varience of life expectancy 

n<-length(Life.expectancy)
lower_ci_sigma_y<-(n-1)*var(Life.expectancy)/qchisq(0.955,n-1)
lower_ci_sigma_y

upper_ci_sigma_y <- 
(n-1)*var(Life.expectancy)/qchisq(0.045,n-1)
upper_ci_sigma_y
Sigma_CI <- c(lower_ci_sigma_y,upper_ci_sigma_y)
Sigma_CI #54.94 #78.94
 # we can see that the value of Sy is in the range -->
var(Life.expectancy)

```

# Question 3 - H

H0: תוחלת אורך החיים של "העולם השמן" יהיה זהה לתוחלת אורך החיים של "העולם הרזה". במילים אחרות - השערת ה0 טוענת שאין תלות בין בימאמאי לתוחלת אורך החיים

העולם השמן - מדינות בהן הביאמאי גדול מחציון הביאמאי בעולם
העולם הרזה - מדינות בהן הבימי גדול מחציון הביאמאי בעולם

H1: תוחלת אורך החיים של העולם השמן _קטנה_ מתוחלת אורך החיים של העולם הרזה

הסבר: אנחנו משערים שהשמנה גוררת ירידה בתוחלת משך החיים ולכן בתוחלת, אורך החיים של העולם השמן יהיה קצר יותר מאורך החיים של העולם הרזה. (ניתן להיזכר בעבודה הקודמת שמקדם המתאם בין אורך חיים להשמנה היה 0.36 כדי לקבל רמז/סיגנל שהקשר קיים). 

We want to test if there are times in the day in which earthquakes are more or less commons. Let $t_i$ be the time of each earthquake $i$ in the day (between $00:00:00$ and $23:59:59$), in units of hours, calculated in (d.). <br> 

Test the null hypothesis $H_0: t_i \sim U[0, 24]$ against the complex alternative 
$$H_0: \mu_{y|x_i > med(X)} = \mu_{y|x_i<med(X)} $$
$$H_1: \mu_{y|x_i > med(X)} < \mu_{y|x_i<med(X)}$$
<br>


In statistical testing, a test statistic is a numerical measure that is used to evaluate the evidence in a sample against a hypothesis. It is calculated from the sample data and is used to decide whether the sample provides sufficient evidence to reject the hypothesis - therfore its $mean(x)$

If the null hypothesis states that the means of two groups are equal, it is assuming that the groups are evenly distributed, or that there is no difference between the groups.


```{r Q3a }
df_low <- df[df$BMI<median(df$BMI),]
df_high <- df[df$BMI>=median(df$BMI),]

# mean(df_low$Life.expectancy)
# mean(df_high$Life.expectancy)

# mean(BMI)
# median(BMI)

y_lower <- df_low$Life.expectancy
y_high <- df_high$Life.expectancy
hist(y_lower)
hist(y_high)
plot(y_high,type = 'line')
lines(y_lower, col='blue')
mean(y_lower)
mean(y_high)

#search for the p-value
#since we don't know the presice variance of the life expctancy we will use t test 

  
p_value <- pt((mean(y_lower) -  mean(y_high)) /(sd(y_lower)/ sqrt(length(y_lower))), df = length(y_lower)-1)

# p_value = exp(-16)*2.798601
p_value

```


```{r}
D_s <-  y_high - y_lower
S2D <- var(y_high) + var(y_lower)  # cov is 0
meanDS <- mean(D_s)

p_value <- pt((meanDS - (mean(y_high)- mean(y_lower)) /sqrt((S2D/(length(y_lower))))), df = length(y_lower)-1)
p_value


pt(meanDS / (sqrt(S2D/length(y_lower))) ,df = length(y_lower)-1)
```

 This is a very small p-value, which suggests that the difference in means between the two groups is statistically significant. In other words, the data provides strong evidence against the null hypothesis, which states that the means of the two groups are equal.

Based on the p-value and the results of our (t-) test, we can conclude that the mean of the "low BMI" group is significantly different from the mean of the "high BMI" group.
Hence we found out that the expected value of Y is smaller then in between the 2 groups.

However, it's important to remember that a p-value of 0 does not necessarily mean that the null hypothesis is definitively false. It simply means that the data provides strong evidence against the null hypothesis.

```{r}
#2.d

alpah = 0.03
p.value = 2.798601e-16
```
p-value that is less than our significance level, then we can conclude that the null hypothesis is rejected



```{r Q3 }
critical_value <- mean(y_lower) + qnorm(0.95)*sd(y_lower)/sqrt(length(y_lower))
critical_value



```


# Old Lab:
A distribution with two centric values can be seen(23,27).no values under 20 or above 32. (that indicates precise data because beyond this range its means extreme underweight or extreme obesity) 

```{r}
hist(Life.expectancy, main = "Life Expectancy", breaks=50, freq = FALSE, col="light blue")
lines(density.default(Life.expectancy))
```

It can be seen that the life expectancy dis' has a long left tail and a center around `r round(mean(Life.expectancy))`, and the latest age is `r round(max(Life.expectancy))`

You can see observations that represent an average life expectancy below the age of 55. We assume that these observations will correspond with people with a low BMI score - third world countries. We will confirm the test later in the work. 

##### Mean, Median, SD, Min, Max,  and Quantiles:

```{r}
# tmp <- df[c('BMI','Life.Expectancy') ]
# tmp
(summary(Life.expectancy))
summary(BMI)
```
$SD_x =$ `r round(sd(BMI), 2)`, and 
$SD_y =$ `r round(sd(Life.expectancy), 2)`

### 3) Our Linear Regression Model
```{r}
reg.bmi.le <- lm(Life.expectancy ~ BMI)
plot(BMI,Life.expectancy, main = "Average BMI VS Average Life Expectency")
abline(reg.bmi.le,lwd=2,col="green")
```

##### Linear Regression Coefficients

```{r, echo=FALSE}
# summary(df2)
a_hat <- cov(Life.expectancy,BMI,  use = "pairwise.complete.obs")/var(BMI,na.rm = "True")
# a_hat
b_hat <- mean(Life.expectancy, na.rm = TRUE)-a_hat*mean(BMI, na.rm = TRUE)
# b_hat
y_hat <- a_hat*BMI + b_hat

###optinal editing - The process of verifying the model, we compared the results of the prediction calculated manually to internal function of R.

#plot(BMI,Life.expectancy, main = "y_hat and the oprator abline are the same line")
#abline(reg.bmi.le,lwd=2,col="green")
#lines(BMI, y_hat)
#plot(lm(Life.expectancy ~ BMI))
```

\br
 $\hat{a} =$ \  `r round(a_hat,3)` is the slope of the regression line. In how much will a person's life expectancy change if their BMI increases by one BMI score.  
\n
 $\hat{b} =$ \ `r round(b_hat,2)` is the intercept of the regression line. It is the size of the life expectency that does not depend on BMI. 
Simply put: a person lives 17.19 years first of all, and then depending on his BMI he will live another $\hat{a}$BMI years.

Pearson Correlation Coefficient: $r(X,Y):= \frac{cov(X,Y)}{SD_X SD_Y} =$ `r round(cor(BMI, Life.expectancy, use = "complete.obs"),3)`
\n The correlation between the variables is positive and high.It suggests that the higher the BMI, the higher the life expectancy.

\n R Square Indicator: $R^2:= r^2(X,Y)=$ `r round(cor(BMI, Life.expectancy, use = "complete.obs")^2,3)`

Our average BMI based model explains `r round(cor(BMI, Life.expectancy, use = "complete.obs")^2,3)` of the variance of averagel life expectancy in a country.


**Note**: The connection is not necessarily linear. Becuase in a linear model, as BMI increases, so does life expectancy. In practice, a BMI over 25 describes a situation of "dangerous obesity" and therefore shortens the lifestyle. A parabolic model may be appropriate.

#### Evaluation - Root Mean Square Error (RMSE)
We showed that  $R^2$  is lower than 0.5, a value that is considered low. However, it can be explained by countless other reasons throughout a person's life expectancy, so relatively it is a variable that explains a considerable percentage of variation

```{r, echo=FALSE}
## the first will be the correlation check
# cor(df2$BMI, df2$Life.Expectancy.Years, use = "complete.obs")

## now we will check what about R_squred
#reg.bmi.le <- lm(Life.expectancy ~ BMI)
#summary(reg.bmi.le)


e<-reg.bmi.le$residuals
RMSE<-round(sqrt(sum(e^2)/(length(BMI)-2)),2)
#RMSE

```

```{r , echo=FALSE}
##R_squred is 0.36, great! lets check it with pearson's number
# security_check <- cor(df2$BMI, df2$Life.Expectancy.Years, use = "complete.obs")**2
# security_check
#The R squared score is 0.52, we will confirm the result by increasing the squared Pearson coefficient and making sure they are equal <insert formula here>. Both indices show a positive linear relationship


res <- residuals(reg.bmi.le)
# res
Sorted_Res <- sort(res)
# head(Sorted_Res) # 92   ,    86     ,   142      ,  28     ,    4   ,     33 ,
# tail(Sorted_Res) #      174  ,     145    ,  47   ,   129     , 143  ,     82

# head(Sorted_Res), tail(Sorted_Res)))
# which(x= c(head(Sorted_Res), tail(Sorted_Res)),arr.ind =TRUE)
df2 <- df[-c(92,86,142,28,4,33,174,145,47,129,143,82),]
# df3 <- df2[,]

reg.bmi.le2 <- lm(df2$Life.expectancy ~ df2$BMI)
#plot(BMI,Life.expectancy)
# summary(reg.bmi.le2)
e_new<-reg.bmi.le2$residuals
RMSE_new<-round(sqrt(sum(e_new^2)/(length(df2$BMI)-2)),2)
#RMSE_new

security_check2 <- cor(df2$BMI, df2$Life.expectancy, use = "complete.obs")**2
# security_check2

##The values of the variables were re-examined after omitting the abnormal observations. We believe that standard deviations will decrease


# summary(df)
# summary(df2)
#summary(lm(df2$Life.expectancy ~ df2$BMI))
#summary(lm(Life.expectancy ~ BMI))

# reg.bmi.le <- lm(Life.expectancy ~ BMI)
# plot(BMI,Life.expectancy, main = "Average BMI VS Average Life Expectency")
# abline(reg.bmi.le,lwd=1.5,col="green")
# abline(reg.bmi.le2,lwd=1,col="blue")
```

$RMSE=$ \ `r RMSE` Years of life expectancy, a small variance of the residuals, suggesting a good accuracy of our model.  \br

### Outlires Handeling
Out of the `r length(df$Country)` observations, we removed the 12 values with most extreme residuals.
We omitted 12 extreme residuals.,and the value of RMSE decreased from `r RMSE` to
`r RMSE_new`.

\n $R^2_{new}:= r_{new}^2(X,Y)=$ `r round(security_check2,2)`

Our average BMI based model explains almost `r ceiling (cor(df2$BMI, df2$Life.expectancy)^2)/2` of the variance of average life expectancy in a country.

#### Demonstrating our model with 3 random samples:

```{r , echo=FALSE}
## the first observation in the df 
# "observation number one - afghanistan,2015,65,19.1"
country<-sample(df2$Country, size = 3)
#country

a_hat <- cov(df2$Life.expectancy, df2$BMI)/var(df2$BMI)
df3 <- cbind(df2[df2$Country %in% country,],a_hat)

#a_hat
b_hat <- mean(df3$Life.expectancy, na.rm = TRUE)-a_hat*mean(df3$BMI, na.rm = TRUE)
#b_hat
df3 <- cbind(df3, b_hat)

Y_hat_LEYears <- round(a_hat*df3$BMI + b_hat,2)
Residual <-round(abs(df3$Life.expectancy-Y_hat_LEYears),2)
df4 <- cbind(df3[df3$Country %in% country,], Y_hat_LEYears)
df4 <- cbind(df4, Residual)

head(df4)
```

```{r eval=FALSE, include=FALSE}

# summary(df2)
a_hat <- cov(df2$Life.expectancy, df2$BMI,  use = "pairwise.complete.obs")/var(df2$BMI,na.rm = "True")
a_hat
b_hat <- mean(df2$Life.expectancy, na.rm = TRUE)-a_hat*mean(df2$BMI, na.rm = TRUE)
b_hat
y_hat <- a_hat*df2$BMI + b_hat

example1 <-y_hat[19.1]
residual1 <- example1 - df2$Life.Expectancy.Years[1]
# residual1


##for the next example we will take ob number 103
df2[103,]
example2 <- y_hat[103]
# example2
residual2 <- example2 - df2$Life.expectancy[103]
# residual2
```
